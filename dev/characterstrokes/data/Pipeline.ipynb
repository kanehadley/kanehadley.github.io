{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def calculate_edges(img, size):\n",
    "    row_coord, col_coord = np.nonzero(-(np.matrix(img.getdata()).reshape(size)) + 255)\n",
    "    # Left, Top, Right, Bottom\n",
    "    return np.min(col_coord) - 1, np.min(row_coord) - 1, np.max(col_coord) + 1, np.max(row_coord) + 1\n",
    "\n",
    "def calculate_normalizing_dimensions(image, theta):\n",
    "    rotated_image = ImageOps.crop(ImageOps.expand(image, 750, 255).rotate(theta), 500)\n",
    "    sides = calculate_edges(rotated_image, (1000, 1000))\n",
    "    return sides\n",
    "\n",
    "def generate_sample(image, theta, normalizing_dimensions):\n",
    "    \"\"\"Rotates an image, downsample it to a 28x28 sample, and then reatures the 28*28 feature vector.\n",
    "    \n",
    "    :param - img\n",
    "        The image to be transformed and downsampled.\n",
    "        \n",
    "    :param - theta\n",
    "        The angle to transform the image before downsampling.\n",
    "    \"\"\"\n",
    "    rotated_image = ImageOps.crop(ImageOps.expand(image, 750, 255).rotate(theta), 500)\n",
    "    \n",
    "    #sides = calculate_edges(rotated_image, (1000, 1000))\n",
    "    \n",
    "    # Image is 1000 x 1000\n",
    "    # normalizing_dimensions is width x height\n",
    "    #width_difference = 1000 - normalizing_dimensions[0]\n",
    "    #height_difference = 1000 - normalizing_dimensions[1]\n",
    "    #expansion = max(width_difference, height_difference) / 2\n",
    "    #compression = min(width_difference, height_difference)\n",
    "    #expansion_image = ImageOps.expand(rotated_image, expansion, 255)\n",
    "    \n",
    "    #if width_difference < height_difference:\n",
    "    #    side_left = (height_difference - width_difference) / 2\n",
    "    #    side_top = 0\n",
    "    #    side_right = expansion_image.size[0] - ((height_difference - width_difference) / 2)\n",
    "    #    side_bottom = expansion_image.size[1]\n",
    "    #else:\n",
    "    #    side_left = 0\n",
    "    #    side_top = (width_difference - height_difference) / 2\n",
    "    #    side_right = expansion_image.size[0]\n",
    "    #    side_bottom = expansion_image.size[1] - ((width_difference - height_difference) / 2)\n",
    "    \n",
    "    #sides = (side_left, side_top, side_right, side_bottom)\n",
    "    \n",
    "    #cropped_image = rotated_image.crop(sides)\n",
    "\n",
    "    cropped_image = rotated_image.crop(normalizing_dimensions)\n",
    "    \n",
    "    # Makes it a square\n",
    "    cropped_max_size = max(cropped_image.size)\n",
    "    \n",
    "    cropped_difference_half = int(((1.0 * cropped_max_size) - min(cropped_image.size)) / 2)\n",
    "    \n",
    "    expanded_cropped_image = ImageOps.expand(cropped_image, cropped_difference_half, 255)\n",
    "    \n",
    "    expanded_cropped_image_size = expanded_cropped_image.size\n",
    "    \n",
    "    # Width is greater\n",
    "    if cropped_image.size[0] > cropped_image.size[1]:\n",
    "        cropped_expanded_cropped_image = expanded_cropped_image.crop((cropped_difference_half,\n",
    "                                                                     0,\n",
    "                                                                     expanded_cropped_image_size[0] - cropped_difference_half,\n",
    "                                                                     expanded_cropped_image_size[1]))\n",
    "    # Height is greater\n",
    "    else:\n",
    "        cropped_expanded_cropped_image = expanded_cropped_image.crop((0,\n",
    "                                                                     cropped_difference_half,\n",
    "                                                                     expanded_cropped_image_size[0],\n",
    "                                                                     expanded_cropped_image_size[1] - cropped_difference_half))\n",
    "    \n",
    "    \n",
    "    #return cropped_expanded_cropped_image\n",
    "    return (-np.array(cropped_expanded_cropped_image.resize((28,28)).getdata()) + 255) * 1.0 / 255\n",
    "    #img_data = np.matrix(list(rotated_img.getdata()))\n",
    "    \n",
    "    \n",
    "    #d = c.reshape((2000, 2000))\n",
    "    #e = (-d) % 255\n",
    "    #e = ImageOps.crop(ImageOps.expand(a, 250, 255).rotate(45), 146)\n",
    "    #math.floor((1000 - 500*math.sqrt(2)) / 2)\n",
    "\n",
    "    #scaled_img = rotated_img.resize((128,128))\n",
    "    \n",
    "    #return scaled_img\n",
    "\n",
    "example = Image.open('characters/traditional_dragon_15.png')\n",
    "example2 = Image.open('characters/traditional_dragon_03.png')\n",
    "\n",
    "z = generate_sample(example2, 90, calculate_normalizing_dimensions(example, 90))\n",
    "#Image.fromarray((-(z.reshape(28,28) * 255) + 255).astype('uint8'), 'L')\n",
    "#z.resize((28,28))\n",
    "#z.shape\n",
    "#z\n",
    "#calculate_prescale_dimensions(example, 90)\n",
    "#y = np.array(z.getdata())\n",
    "#y.size\n",
    "#z.size\n",
    "#Image.fromarray(y.reshape(445,445), 'I')\n",
    "#Image.frombuffer('I', (445, 445), y, 'raw', 'I', 0, 255)\n",
    "#Image.fromarray(np.array(z.getdata()).astype('uint8').reshape((445,445)))\n",
    "\n",
    "def view_feature_array(array, size):\n",
    "    return Image.fromarray((-(array.reshape(size) * 255) + 255).astype('uint8'), 'L')\n",
    "\n",
    "#view_feature_array(z, (28, 28))\n",
    "\n",
    "#view_feature_array(np.array([generate_sample(example, 90, calculate_normalizing_dimensions(example, 90)),\n",
    "#         generate_sample(example2, 90, calculate_normalizing_dimensions(example, 90))])[1],(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#view_feature_array(z3[1], (28,28))\n",
    "\n",
    "name_class_list = [\n",
    "    ('traditional_dragon_00.png', 0),\n",
    "    ('traditional_dragon_01.png', 1),\n",
    "    ('traditional_dragon_02.png', 2),\n",
    "    ('traditional_dragon_03.png', 3),\n",
    "    ('traditional_dragon_04.png', 4),\n",
    "    ('traditional_dragon_05.png', 5),\n",
    "    ('traditional_dragon_06.png', 6),\n",
    "    ('traditional_dragon_07.png', 7),\n",
    "    ('traditional_dragon_08.png', 8),\n",
    "    ('traditional_dragon_09.png', 9),\n",
    "    ('traditional_dragon_10.png', 10),\n",
    "    ('traditional_dragon_11.png', 11),\n",
    "    ('traditional_dragon_12.png', 12),\n",
    "    ('traditional_dragon_13.png', 13),\n",
    "    ('traditional_dragon_14.png', 14),\n",
    "    ('traditional_dragon_15.png', 15)]\n",
    "#    ('simplified_dragon_00.png', 16),\n",
    "#    ('simplified_dragon_01.png', 17),\n",
    "#    ('simplified_dragon_02.png', 18),\n",
    "#    ('simplified_dragon_03.png', 19),\n",
    "#    ('simplified_dragon_04.png', 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_class_list = map(lambda x: (Image.open('characters/' + x[0]), x[1]), name_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data\n",
      "Generating images for image 1  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 2  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 3  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 4  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 5  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 6  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 7  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 8  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 9  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 10  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 11  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 12  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 13  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 14  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 15  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating images for image 16  out of 16\n",
      "Generated 10 samples out of 10 .\n",
      "Generating testing data\n",
      "Generating images for image 1  out of 16\n",
      "Generating images for image 2  out of 16\n",
      "Generating images for image 3  out of 16\n",
      "Generating images for image 4  out of 16\n",
      "Generating images for image 5  out of 16\n",
      "Generating images for image 6  out of 16\n",
      "Generating images for image 7  out of 16\n",
      "Generating images for image 8  out of 16\n",
      "Generating images for image 9  out of 16\n",
      "Generating images for image 10  out of 16\n",
      "Generating images for image 11  out of 16\n",
      "Generating images for image 12  out of 16\n",
      "Generating images for image 13  out of 16\n",
      "Generating images for image 14  out of 16\n",
      "Generating images for image 15  out of 16\n",
      "Generating images for image 16  out of 16\n"
     ]
    }
   ],
   "source": [
    "def generate_data_sets(image_class_pairs, test_set_size):\n",
    "    train_set_size = 10 * test_set_size\n",
    "    sub_image_pairs = image_class_pairs[:-1]\n",
    "    main_image_pair = image_class_pairs[-1]\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    \n",
    "    # Creating training data\n",
    "    print 'Generating training data'\n",
    "    aggregated_generated_image_list = []\n",
    "    aggregated_generated_class_list = []\n",
    "    \n",
    "    for pair_index, pair in enumerate(image_class_pairs):\n",
    "        print 'Generating images for image', (pair_index + 1), ' out of', len(image_class_pairs)\n",
    "        \n",
    "        sampled_rotations = np.random.normal(mu, sigma, train_set_size) * 360\n",
    "        generated_image_list = []\n",
    "        generated_class_list = []\n",
    "        \n",
    "        for index, theta in enumerate(sampled_rotations):\n",
    "            normalizing_size = calculate_normalizing_dimensions(main_image_pair[0], theta)\n",
    "            sample = generate_sample(pair[0],\n",
    "                                     theta,\n",
    "                                     normalizing_size)\n",
    "            generated_image_list.append(sample)\n",
    "            generated_class_list.append(pair[1])\n",
    "            if 0 == (index + 1) % 10:\n",
    "                print 'Generated', (index + 1), 'samples out of', train_set_size, '.'\n",
    "    \n",
    "        combined_generated_image_array = np.vstack(generated_image_list)\n",
    "        aggregated_generated_image_list.append(combined_generated_image_array)\n",
    "        \n",
    "        combined_generated_class_array = np.array(generated_class_list)\n",
    "        aggregated_generated_class_list.append(combined_generated_class_array)\n",
    "        \n",
    "    aggregated_generated_image_array = np.vstack(aggregated_generated_image_list)\n",
    "    aggregated_generated_class_array = np.hstack(aggregated_generated_class_list)\n",
    "    \n",
    "    train_x = aggregated_generated_image_array\n",
    "    train_y = aggregated_generated_class_array\n",
    "    \n",
    "    \n",
    "    # Creating testing data\n",
    "    print 'Generating testing data'\n",
    "    aggregated_generated_image_list = []\n",
    "    aggregated_generated_class_list = []\n",
    "    \n",
    "    for pair_index, pair in enumerate(image_class_pairs):\n",
    "        print 'Generating images for image', (pair_index + 1), ' out of', len(image_class_pairs)\n",
    "        \n",
    "        sampled_rotations = np.random.normal(mu, sigma, test_set_size) * 360\n",
    "        generated_image_list = []\n",
    "        generated_class_list = []\n",
    "        \n",
    "        for index, theta in enumerate(sampled_rotations):\n",
    "            normalizing_size = calculate_normalizing_dimensions(main_image_pair[0], theta)\n",
    "            sample = generate_sample(pair[0],\n",
    "                                     theta,\n",
    "                                     normalizing_size)\n",
    "            generated_image_list.append(sample)\n",
    "            generated_class_list.append(pair[1])\n",
    "            if 0 == (index + 1) % 10:\n",
    "                print 'Generated', (index + 1), 'samples out of', train_set_size, '.'\n",
    "    \n",
    "        combined_generated_image_array = np.vstack(generated_image_list)\n",
    "        aggregated_generated_image_list.append(combined_generated_image_array)\n",
    "        \n",
    "        combined_generated_class_array = np.array(generated_class_list)\n",
    "        aggregated_generated_class_list.append(combined_generated_class_array)\n",
    "        \n",
    "    aggregated_generated_image_array = np.vstack(aggregated_generated_image_list)\n",
    "    aggregated_generated_class_array = np.hstack(aggregated_generated_class_list)\n",
    "    \n",
    "    test_x = aggregated_generated_image_array\n",
    "    test_y = aggregated_generated_class_array\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "tr_x, tr_y, te_x, te_y = generate_data_sets(image_class_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

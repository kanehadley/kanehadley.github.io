{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "#import numpy as np\n",
    "import autograd.numpy as np\n",
    "\n",
    "def calculate_edges(img, size):\n",
    "    row_coord, col_coord = np.nonzero(-(np.matrix(img.getdata()).reshape(size)) + 255)\n",
    "    # Left, Top, Right, Bottom\n",
    "    return np.min(col_coord) - 1, np.min(row_coord) - 1, np.max(col_coord) + 1, np.max(row_coord) + 1\n",
    "\n",
    "def calculate_normalizing_dimensions(image, theta):\n",
    "    rotated_image = ImageOps.crop(ImageOps.expand(image, 750, 255).rotate(theta), 500)\n",
    "    sides = calculate_edges(rotated_image, (1000, 1000))\n",
    "    return sides\n",
    "\n",
    "def generate_sample(image, theta, normalizing_dimensions):\n",
    "    \"\"\"Rotates an image, downsample it to a 28x28 sample, and then reatures the 28*28 feature vector.\n",
    "    \n",
    "    :param - img\n",
    "        The image to be transformed and downsampled.\n",
    "        \n",
    "    :param - theta\n",
    "        The angle to transform the image before downsampling.\n",
    "    \"\"\"\n",
    "    rotated_image = ImageOps.crop(ImageOps.expand(image, 750, 255).rotate(theta), 500)\n",
    "    \n",
    "    #sides = calculate_edges(rotated_image, (1000, 1000))\n",
    "    \n",
    "    # Image is 1000 x 1000\n",
    "    # normalizing_dimensions is width x height\n",
    "    #width_difference = 1000 - normalizing_dimensions[0]\n",
    "    #height_difference = 1000 - normalizing_dimensions[1]\n",
    "    #expansion = max(width_difference, height_difference) / 2\n",
    "    #compression = min(width_difference, height_difference)\n",
    "    #expansion_image = ImageOps.expand(rotated_image, expansion, 255)\n",
    "    \n",
    "    #if width_difference < height_difference:\n",
    "    #    side_left = (height_difference - width_difference) / 2\n",
    "    #    side_top = 0\n",
    "    #    side_right = expansion_image.size[0] - ((height_difference - width_difference) / 2)\n",
    "    #    side_bottom = expansion_image.size[1]\n",
    "    #else:\n",
    "    #    side_left = 0\n",
    "    #    side_top = (width_difference - height_difference) / 2\n",
    "    #    side_right = expansion_image.size[0]\n",
    "    #    side_bottom = expansion_image.size[1] - ((width_difference - height_difference) / 2)\n",
    "    \n",
    "    #sides = (side_left, side_top, side_right, side_bottom)\n",
    "    \n",
    "    #cropped_image = rotated_image.crop(sides)\n",
    "\n",
    "    cropped_image = rotated_image.crop(normalizing_dimensions)\n",
    "    \n",
    "    # Makes it a square\n",
    "    cropped_max_size = max(cropped_image.size)\n",
    "    \n",
    "    cropped_difference_half = int(((1.0 * cropped_max_size) - min(cropped_image.size)) / 2)\n",
    "    \n",
    "    expanded_cropped_image = ImageOps.expand(cropped_image, cropped_difference_half, 255)\n",
    "    \n",
    "    expanded_cropped_image_size = expanded_cropped_image.size\n",
    "    \n",
    "    # Width is greater\n",
    "    if cropped_image.size[0] > cropped_image.size[1]:\n",
    "        cropped_expanded_cropped_image = expanded_cropped_image.crop((cropped_difference_half,\n",
    "                                                                     0,\n",
    "                                                                     expanded_cropped_image_size[0] - cropped_difference_half,\n",
    "                                                                     expanded_cropped_image_size[1]))\n",
    "    # Height is greater\n",
    "    else:\n",
    "        cropped_expanded_cropped_image = expanded_cropped_image.crop((0,\n",
    "                                                                     cropped_difference_half,\n",
    "                                                                     expanded_cropped_image_size[0],\n",
    "                                                                     expanded_cropped_image_size[1] - cropped_difference_half))\n",
    "    \n",
    "    \n",
    "    #return cropped_expanded_cropped_image\n",
    "    return (-np.array(cropped_expanded_cropped_image.resize((28,28)).getdata()) + 255) * 1.0 / 255\n",
    "    #img_data = np.matrix(list(rotated_img.getdata()))\n",
    "    \n",
    "    \n",
    "    #d = c.reshape((2000, 2000))\n",
    "    #e = (-d) % 255\n",
    "    #e = ImageOps.crop(ImageOps.expand(a, 250, 255).rotate(45), 146)\n",
    "    #math.floor((1000 - 500*math.sqrt(2)) / 2)\n",
    "\n",
    "    #scaled_img = rotated_img.resize((128,128))\n",
    "    \n",
    "    #return scaled_img\n",
    "\n",
    "example = Image.open('characters/traditional_dragon_15.png')\n",
    "example2 = Image.open('characters/traditional_dragon_03.png')\n",
    "\n",
    "z = generate_sample(example2, 90, calculate_normalizing_dimensions(example, 90))\n",
    "#Image.fromarray((-(z.reshape(28,28) * 255) + 255).astype('uint8'), 'L')\n",
    "#z.resize((28,28))\n",
    "#z.shape\n",
    "#z\n",
    "#calculate_prescale_dimensions(example, 90)\n",
    "#y = np.array(z.getdata())\n",
    "#y.size\n",
    "#z.size\n",
    "#Image.fromarray(y.reshape(445,445), 'I')\n",
    "#Image.frombuffer('I', (445, 445), y, 'raw', 'I', 0, 255)\n",
    "#Image.fromarray(np.array(z.getdata()).astype('uint8').reshape((445,445)))\n",
    "\n",
    "def view_feature_array(array, size):\n",
    "    return Image.fromarray((-(array.reshape(size) * 255) + 255).astype('uint8'), 'L')\n",
    "\n",
    "#view_feature_array(z, (28, 28))\n",
    "\n",
    "#view_feature_array(np.array([generate_sample(example, 90, calculate_normalizing_dimensions(example, 90)),\n",
    "#         generate_sample(example2, 90, calculate_normalizing_dimensions(example, 90))])[1],(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#view_feature_array(z3[1], (28,28))\n",
    "\n",
    "name_class_list = [\n",
    "    ('traditional_dragon_00.png', 0),\n",
    "    ('traditional_dragon_01.png', 1),\n",
    "    ('traditional_dragon_02.png', 2),\n",
    "    ('traditional_dragon_03.png', 3),\n",
    "    ('traditional_dragon_04.png', 4),\n",
    "    ('traditional_dragon_05.png', 5),\n",
    "    ('traditional_dragon_06.png', 6),\n",
    "    ('traditional_dragon_07.png', 7),\n",
    "    ('traditional_dragon_08.png', 8),\n",
    "    ('traditional_dragon_09.png', 9),\n",
    "    ('traditional_dragon_10.png', 10),\n",
    "    ('traditional_dragon_11.png', 11),\n",
    "    ('traditional_dragon_12.png', 12),\n",
    "    ('traditional_dragon_13.png', 13),\n",
    "    ('traditional_dragon_14.png', 14),\n",
    "    ('traditional_dragon_15.png', 15),\n",
    "    ('simplified_dragon_00.png', 16),\n",
    "    ('simplified_dragon_01.png', 17),\n",
    "    ('simplified_dragon_02.png', 18),\n",
    "    ('simplified_dragon_03.png', 19),\n",
    "    ('simplified_dragon_04.png', 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_class_list = map(lambda x: (Image.open('characters/' + x[0]), x[1]), name_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data\n",
      "Generating images for image 1  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 2  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 3  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 4  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 5  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 6  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 7  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 8  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 9  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 10  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 11  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 12  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 13  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 14  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 15  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating images for image 16  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generated 20 samples out of 100 .\n",
      "Generated 30 samples out of 100 .\n",
      "Generated 40 samples out of 100 .\n",
      "Generated 50 samples out of 100 .\n",
      "Generated 60 samples out of 100 .\n",
      "Generated 70 samples out of 100 .\n",
      "Generated 80 samples out of 100 .\n",
      "Generated 90 samples out of 100 .\n",
      "Generated 100 samples out of 100 .\n",
      "Generating testing data\n",
      "Generating images for image 1  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 2  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 3  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 4  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 5  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 6  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 7  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 8  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 9  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 10  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 11  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 12  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 13  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 14  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 15  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating images for image 16  out of 16\n",
      "Generated 10 samples out of 100 .\n",
      "Generating training data\n",
      "Generating images for image 1  out of 9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-9a6e04896d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mall_image_class_pairs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_class_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_counts_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mimage_class_data_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimage_class_entry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_class_entry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_image_class_pairs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mtr_all_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mquad_tuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquad_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_class_data_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-9a6e04896d58>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(image_class_entry)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mall_image_class_pairs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image_class_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_counts_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mimage_class_data_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimage_class_entry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenerate_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_class_entry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_image_class_pairs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mtr_all_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mquad_tuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquad_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_class_data_sets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-9a6e04896d58>\u001b[0m in \u001b[0;36mgenerate_data_sets\u001b[0;34m(image_class_pairs, test_set_size)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_rotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mnormalizing_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_normalizing_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_image_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             sample = generate_sample(pair[0],\n\u001b[1;32m     49\u001b[0m                                      \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7fcb17e0ce13>\u001b[0m in \u001b[0;36mcalculate_normalizing_dimensions\u001b[0;34m(image, theta)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_normalizing_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrotated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotated_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-7fcb17e0ce13>\u001b[0m in \u001b[0;36mcalculate_edges\u001b[0;34m(img, size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mrow_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Left, Top, Right, Bottom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_coord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_coord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_coord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_coord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "name_counts_list = [\n",
    "    ('traditional_dragon', 16),\n",
    "    ('traditional_beauty', 9),\n",
    "    ('traditional_love', 13),\n",
    "    ('simplified_dragon', 5),\n",
    "    \n",
    "]\n",
    "\n",
    "def generate_image_class_pairs(name_counts_pairs):\n",
    "    global_class_index = 0\n",
    "    global_image_class_list = []\n",
    "    \n",
    "    for pair in name_counts_pairs:\n",
    "        local_image_class_list = []\n",
    "        for index in range(pair[1]):\n",
    "            local_image_class_list.append((Image.open('characters/' + pair[0] + '_' + ('0' + str(index) if index < 10 else str(index)) + '.png'), global_class_index))\n",
    "            global_class_index += 1\n",
    "        global_image_class_list.append(local_image_class_list)\n",
    "    \n",
    "    return global_image_class_list\n",
    "    #return map(lambda pair: map(lambda index: (Image.open('characters/' + pair[0] + '_' + ('0' + str(index) if index < 10 else str(index)) + '.png'), pair[1]),\n",
    "    #                            range(pair[1])),\n",
    "    #           name_counts_pairs)\n",
    "\n",
    "def generate_data_sets(image_class_pairs, test_set_size):\n",
    "    train_set_size = 10 * test_set_size\n",
    "    sub_image_pairs = image_class_pairs[:-1]\n",
    "    main_image_pair = image_class_pairs[-1]\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    \n",
    "    # Creating training data\n",
    "    print 'Generating training data'\n",
    "    aggregated_generated_image_list = []\n",
    "    aggregated_generated_class_list = []\n",
    "    \n",
    "    for pair_index, pair in enumerate(image_class_pairs):\n",
    "        print 'Generating images for image', (pair_index + 1), ' out of', len(image_class_pairs)\n",
    "        \n",
    "        sampled_rotations = np.random.normal(mu, sigma, train_set_size) * 360\n",
    "        generated_image_list = []\n",
    "        generated_class_list = []\n",
    "        \n",
    "        for index, theta in enumerate(sampled_rotations):\n",
    "            normalizing_size = calculate_normalizing_dimensions(main_image_pair[0], theta)\n",
    "            sample = generate_sample(pair[0],\n",
    "                                     theta,\n",
    "                                     normalizing_size)\n",
    "            generated_image_list.append(sample)\n",
    "            generated_class_list.append(pair[1])\n",
    "            if 0 == (index + 1) % 10:\n",
    "                print 'Generated', (index + 1), 'samples out of', train_set_size, '.'\n",
    "    \n",
    "        combined_generated_image_array = np.vstack(generated_image_list)\n",
    "        aggregated_generated_image_list.append(combined_generated_image_array)\n",
    "        \n",
    "        combined_generated_class_array = np.array(generated_class_list)\n",
    "        aggregated_generated_class_list.append(combined_generated_class_array)\n",
    "        \n",
    "    aggregated_generated_image_array = np.vstack(aggregated_generated_image_list)\n",
    "    aggregated_generated_class_array = np.hstack(aggregated_generated_class_list)\n",
    "    \n",
    "    train_x = aggregated_generated_image_array\n",
    "    train_y = aggregated_generated_class_array\n",
    "    \n",
    "    \n",
    "    # Creating testing data\n",
    "    print 'Generating testing data'\n",
    "    aggregated_generated_image_list = []\n",
    "    aggregated_generated_class_list = []\n",
    "    \n",
    "    for pair_index, pair in enumerate(image_class_pairs):\n",
    "        print 'Generating images for image', (pair_index + 1), ' out of', len(image_class_pairs)\n",
    "        \n",
    "        sampled_rotations = np.random.normal(mu, sigma, test_set_size) * 360\n",
    "        generated_image_list = []\n",
    "        generated_class_list = []\n",
    "        \n",
    "        for index, theta in enumerate(sampled_rotations):\n",
    "            normalizing_size = calculate_normalizing_dimensions(main_image_pair[0], theta)\n",
    "            sample = generate_sample(pair[0],\n",
    "                                     theta,\n",
    "                                     normalizing_size)\n",
    "            generated_image_list.append(sample)\n",
    "            generated_class_list.append(pair[1])\n",
    "            if 0 == (index + 1) % 10:\n",
    "                print 'Generated', (index + 1), 'samples out of', train_set_size, '.'\n",
    "    \n",
    "        combined_generated_image_array = np.vstack(generated_image_list)\n",
    "        aggregated_generated_image_list.append(combined_generated_image_array)\n",
    "        \n",
    "        combined_generated_class_array = np.array(generated_class_list)\n",
    "        aggregated_generated_class_list.append(combined_generated_class_array)\n",
    "        \n",
    "    aggregated_generated_image_array = np.vstack(aggregated_generated_image_list)\n",
    "    aggregated_generated_class_array = np.hstack(aggregated_generated_class_list)\n",
    "    \n",
    "    test_x = aggregated_generated_image_array\n",
    "    test_y = aggregated_generated_class_array\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "#tr_x, tr_y, te_x, te_y = generate_data_sets(image_class_list, 1)\n",
    "\n",
    "all_image_class_pairs_list = generate_image_class_pairs(name_counts_list)\n",
    "image_class_data_sets = map(lambda image_class_entry: generate_data_sets(image_class_entry, 10), all_image_class_pairs_list)\n",
    "\n",
    "tr_all_x = np.vstack(map(lambda quad_tuple: quad_tuple[0], image_class_data_sets))\n",
    "tr_all_y = np.hstack(map(lambda quad_tuple: quad_tuple[1], image_class_data_sets))\n",
    "te_all_x = np.vstack(map(lambda quad_tuple: quad_tuple[2], image_class_data_sets))\n",
    "te_all_y = np.hstack(map(lambda quad_tuple: quad_tuple[3], image_class_data_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_all_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAH0CAAAAADuvYBWAAARdklEQVR4nO2d2ZbjOK5FSWf////e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\nT8j/AFY4BA1Oy7vjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=500x500 at 0x110F2FF10>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_image_class_pairs_list[0][15][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "#import autograd.numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN THIS! HERE FOR EXAMPLE ONLY!\n",
    "\n",
    "import cPickle, gzip, numpy\n",
    "\n",
    "# Load the dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "def shared_dataset(data_xy):\n",
    "    \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "    The reason we store our dataset in shared variables is to allow\n",
    "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    is needed (the default behaviour if the data is not in a shared\n",
    "    variable) would lead to a large decrease in performance.\n",
    "    \"\"\"\n",
    "    data_x, data_y = data_xy\n",
    "    #shared_x = theano.shared(numpy.asarray(data_x, dtype=theano.config.floatX))\n",
    "    #shared_y = theano.shared(numpy.asarray(data_y, dtype=theano.config.floatX))\n",
    "    # When storing data on the GPU it has to be stored as floats\n",
    "    # therefore we will store the labels as ``floatX`` as well\n",
    "    # (``shared_y`` does exactly that). But during our computations\n",
    "    # we need them as ints (we use labels as index, and if they are\n",
    "    # floats it doesn't make sense) therefore instead of returning\n",
    "    # ``shared_y`` we will have to cast it to int. This little hack\n",
    "    # lets us get around this issue\n",
    "    #return shared_x, T.cast(shared_y, 'int32')\n",
    "    return data_x, data_y\n",
    "\n",
    "test_set_x, test_set_y = shared_dataset(test_set)\n",
    "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "train_set_x, train_set_y = shared_dataset(train_set)\n",
    "\n",
    "batch_size = 500    # size of the minibatch\n",
    "\n",
    "# accessing the third minibatch of the training set\n",
    "\n",
    "data  = train_set_x[2 * batch_size: 3 * batch_size]\n",
    "label = train_set_y[2 * batch_size: 3 * batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "def linear_activation(W, b, X):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    \"\"\"\n",
    "    return np.dot(X, W) + b\n",
    "\n",
    "# P(Y = i | x, W, b)\n",
    "# p_y_given_x\n",
    "def softmax(W, b, X):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    \"\"\"\n",
    "    return np.exp(np.dot(X, W) + b) / np.sum(np.exp(np.dot(X, W) + b), axis=1)[:, None]\n",
    "\n",
    "# y_pred\n",
    "def prediction(W, b, X):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    \"\"\"\n",
    "    return np.argmax(softmax(W, b, X), axis=1)\n",
    "\n",
    "def likelihood(W, b, X, Y):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    :param - Y - n classifications (one for each sample)\n",
    "    \"\"\"\n",
    "    return softmax(W, b, X)[np.arange(Y.shape[0]), Y]\n",
    "\n",
    "def negative_log_likelihood(W, b, X, Y):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    :param - Y - n classifications (one for each sample)\n",
    "    \"\"\"    \n",
    "    return -likelihood(W, b, X, Y)\n",
    "\n",
    "def loss(W, b, X, Y):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    :param - Y - n classifications (one for each sample)\n",
    "    \"\"\"\n",
    "    return np.mean(negative_log_likelihood(W, b, X, Y))\n",
    "\n",
    "def errors(W, b, X, Y):\n",
    "    \"\"\"\n",
    "    :param - W - m input nodes (one for each feature) with c output nodes (one for each class)\n",
    "    :param - b - c bias weight nodes (one for each class)\n",
    "    :param - X - n samples with m features each, nxm matrix\n",
    "    :param - Y - n classifications (one for each sample)\n",
    "    \"\"\"\n",
    "    return np.mean(np.not_equal(prediction(W, b, X), Y))\n",
    "\n",
    "loss_grad_W = grad(loss, 0)\n",
    "loss_grad_b = grad(loss, 1)\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, n_in, n_out, learning_rate=0.13):\n",
    "        self.W = np.random.rand(n_in * n_out).reshape(n_in, n_out)\n",
    "        self.b = np.zeros((n_out,), dtype=np.float64)\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "def logistic_regression_update_values(lr, X, Y):\n",
    "    W_update = lr.W - lr.learning_rate * loss_grad_W(lr.W, lr.b, X, Y)\n",
    "    b_update = lr.b - lr.learning_rate * loss_grad_b(lr.W, lr.b, X, Y)\n",
    "    \n",
    "    return W_update, b_update\n",
    "        \n",
    "    \n",
    "def logistic_regression_training_environment(lr, data, labels, epochs=100, batch_size=500):\n",
    "    n_train_batches = data.shape[0] // batch_size\n",
    "    \n",
    "    for epoch_count in range(epochs):\n",
    "        for index in range(n_train_batches):\n",
    "            X_batch = data[index * batch_size: (index + 1) * batch_size]\n",
    "            Y_batch = labels[index * batch_size: (index + 1) * batch_size]\n",
    "            \n",
    "            lr.W, lr.b = logistic_regression_update_values(lr, X_batch, Y_batch)\n",
    "            \n",
    "        if 0 == epoch_count % 100:\n",
    "            print 'Epoch:', epoch_count, ', Error rate:', errors(lr.W, lr.b, data, labels)\n",
    "            \n",
    "def logistic_regression_demo():\n",
    "    from autograd import grad\n",
    "    import autograd.numpy as np\n",
    "    import cPickle, gzip, numpy\n",
    "\n",
    "    # Load the dataset\n",
    "    demo_f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    demo_train_set, demo_valid_set, demo_test_set = cPickle.load(demo_f)\n",
    "    demo_f.close()\n",
    "\n",
    "    demo_test_set_x, demo_test_set_y = demo_test_set\n",
    "    demo_valid_set_x, demo_valid_set_y = demo_valid_set\n",
    "    demo_train_set_x, demo_train_set_y = demo_train_set\n",
    "\n",
    "    demo_n_in = 28*28\n",
    "    demo_n_out = 10\n",
    "    demo_learning_rate = 0.13\n",
    "    \n",
    "    demo_c = LogisticRegression(demo_n_in, demo_n_out, demo_learning_rate)\n",
    "    \n",
    "    print \"Baseline:\", errors(c.W, c.b, demo_test_set_x, demo_test_set_y)\n",
    "    \n",
    "    logistic_regression_training_environment(demo_c, demo_train_set_x, demo_train_set_y, 1000)\n",
    "    \n",
    "    print \"End of Training:\", errors(c.W, c.b, demo_test_set_x, demo_test_set_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chr_in = 28*28\n",
    "#chr_out = len(image_class_list)\n",
    "chr_out = np.max(tr_all_y) + 1\n",
    "chr_learning_rate = 0.13\n",
    "\n",
    "c = LogisticRegression(chr_in, chr_out, chr_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Error Rate: 0.952380952381\n"
     ]
    }
   ],
   "source": [
    "print 'Baseline Error Rate:', errors(c.W, c.b, te_all_x, te_all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 , Error rate: 0.914285714286\n",
      "Epoch: 100 , Error rate: 0.666666666667\n",
      "Epoch: 200 , Error rate: 0.571428571429\n",
      "Epoch: 300 , Error rate: 0.542857142857\n",
      "Epoch: 400 , Error rate: 0.52380952381\n",
      "Epoch: 500 , Error rate: 0.5\n",
      "Epoch: 600 , Error rate: 0.466666666667\n",
      "Epoch: 700 , Error rate: 0.428571428571\n",
      "Epoch: 800 , Error rate: 0.404761904762\n",
      "Epoch: 900 , Error rate: 0.390476190476\n",
      "Epoch: 1000 , Error rate: 0.385714285714\n",
      "Epoch: 1100 , Error rate: 0.380952380952\n",
      "Epoch: 1200 , Error rate: 0.37619047619\n",
      "Epoch: 1300 , Error rate: 0.366666666667\n",
      "Epoch: 1400 , Error rate: 0.366666666667\n",
      "Epoch: 1500 , Error rate: 0.366666666667\n",
      "Epoch: 1600 , Error rate: 0.352380952381\n",
      "Epoch: 1700 , Error rate: 0.352380952381\n",
      "Epoch: 1800 , Error rate: 0.352380952381\n",
      "Epoch: 1900 , Error rate: 0.347619047619\n",
      "Epoch: 2000 , Error rate: 0.347619047619\n",
      "Epoch: 2100 , Error rate: 0.347619047619\n",
      "Epoch: 2200 , Error rate: 0.342857142857\n",
      "Epoch: 2300 , Error rate: 0.333333333333\n",
      "Epoch: 2400 , Error rate: 0.328571428571\n",
      "Epoch: 2500 , Error rate: 0.32380952381\n",
      "Epoch: 2600 , Error rate: 0.32380952381\n",
      "Epoch: 2700 , Error rate: 0.32380952381\n",
      "Epoch: 2800 , Error rate: 0.32380952381\n",
      "Epoch: 2900 , Error rate: 0.32380952381\n",
      "Epoch: 3000 , Error rate: 0.314285714286\n",
      "Epoch: 3100 , Error rate: 0.309523809524\n",
      "Epoch: 3200 , Error rate: 0.309523809524\n",
      "Epoch: 3300 , Error rate: 0.304761904762\n",
      "Epoch: 3400 , Error rate: 0.304761904762\n",
      "Epoch: 3500 , Error rate: 0.304761904762\n",
      "Epoch: 3600 , Error rate: 0.304761904762\n",
      "Epoch: 3700 , Error rate: 0.3\n",
      "Epoch: 3800 , Error rate: 0.3\n",
      "Epoch: 3900 , Error rate: 0.3\n",
      "Epoch: 4000 , Error rate: 0.3\n",
      "Epoch: 4100 , Error rate: 0.3\n",
      "Epoch: 4200 , Error rate: 0.3\n",
      "Epoch: 4300 , Error rate: 0.3\n",
      "Epoch: 4400 , Error rate: 0.3\n",
      "Epoch: 4500 , Error rate: 0.3\n",
      "Epoch: 4600 , Error rate: 0.3\n",
      "Epoch: 4700 , Error rate: 0.3\n",
      "Epoch: 4800 , Error rate: 0.3\n",
      "Epoch: 4900 , Error rate: 0.295238095238\n",
      "Epoch: 5000 , Error rate: 0.285714285714\n",
      "Epoch: 5100 , Error rate: 0.285714285714\n",
      "Epoch: 5200 , Error rate: 0.285714285714\n",
      "Epoch: 5300 , Error rate: 0.285714285714\n",
      "Epoch: 5400 , Error rate: 0.285714285714\n",
      "Epoch: 5500 , Error rate: 0.285714285714\n",
      "Epoch: 5600 , Error rate: 0.285714285714\n",
      "Epoch: 5700 , Error rate: 0.285714285714\n",
      "Epoch: 5800 , Error rate: 0.285714285714\n",
      "Epoch: 5900 , Error rate: 0.285714285714\n",
      "Epoch: 6000 , Error rate: 0.285714285714\n",
      "Epoch: 6100 , Error rate: 0.285714285714\n",
      "Epoch: 6200 , Error rate: 0.285714285714\n",
      "Epoch: 6300 , Error rate: 0.285714285714\n",
      "Epoch: 6400 , Error rate: 0.285714285714\n",
      "Epoch: 6500 , Error rate: 0.285714285714\n",
      "Epoch: 6600 , Error rate: 0.285714285714\n",
      "Epoch: 6700 , Error rate: 0.285714285714\n",
      "Epoch: 6800 , Error rate: 0.285714285714\n",
      "Epoch: 6900 , Error rate: 0.285714285714\n",
      "Epoch: 7000 , Error rate: 0.285714285714\n",
      "Epoch: 7100 , Error rate: 0.285714285714\n",
      "Epoch: 7200 , Error rate: 0.285714285714\n",
      "Epoch: 7300 , Error rate: 0.285714285714\n",
      "Epoch: 7400 , Error rate: 0.285714285714\n",
      "Epoch: 7500 , Error rate: 0.285714285714\n",
      "Epoch: 7600 , Error rate: 0.285714285714\n",
      "Epoch: 7700 , Error rate: 0.285714285714\n",
      "Epoch: 7800 , Error rate: 0.285714285714\n",
      "Epoch: 7900 , Error rate: 0.285714285714\n",
      "Epoch: 8000 , Error rate: 0.285714285714\n",
      "Epoch: 8100 , Error rate: 0.285714285714\n",
      "Epoch: 8200 , Error rate: 0.285714285714\n",
      "Epoch: 8300 , Error rate: 0.285714285714\n",
      "Epoch: 8400 , Error rate: 0.285714285714\n",
      "Epoch: 8500 , Error rate: 0.285714285714\n",
      "Epoch: 8600 , Error rate: 0.285714285714\n",
      "Epoch: 8700 , Error rate: 0.285714285714\n",
      "Epoch: 8800 , Error rate: 0.285714285714\n",
      "Epoch: 8900 , Error rate: 0.285714285714\n",
      "Epoch: 9000 , Error rate: 0.285714285714\n",
      "Epoch: 9100 , Error rate: 0.285714285714\n",
      "Epoch: 9200 , Error rate: 0.285714285714\n",
      "Epoch: 9300 , Error rate: 0.285714285714\n",
      "Epoch: 9400 , Error rate: 0.285714285714\n",
      "Epoch: 9500 , Error rate: 0.285714285714\n",
      "Epoch: 9600 , Error rate: 0.285714285714\n",
      "Epoch: 9700 , Error rate: 0.285714285714\n",
      "Epoch: 9800 , Error rate: 0.285714285714\n",
      "Epoch: 9900 , Error rate: 0.285714285714\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_training_environment(c, tr_all_x, tr_all_y, epochs=10000, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "save_file = open('pickledModel', 'wb')  # this will overwrite current contents\n",
    "#cPickle.dump(w.get_value(borrow=True), save_file, -1)  # the -1 is for HIGHEST_PROTOCOL\n",
    "#cPickle.dump(v.get_value(borrow=True), save_file, -1)  # .. and it triggers much more efficient\n",
    "#cPickle.dump(u.get_value(borrow=True), save_file, -1)  # .. storage than numpy's default\n",
    "cPickle.dump(c.W, save_file, -1)\n",
    "cPickle.dump(c.b, save_file, -1)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_file = open('pickledModel')\n",
    "#w.set_value(cPickle.load(save_file), borrow=True)\n",
    "#v.set_value(cPickle.load(save_file), borrow=True)\n",
    "#u.set_value(cPickle.load(save_file), borrow=True)\n",
    "\n",
    "pullW = cPickle.load(save_file)\n",
    "pullB = cPickle.load(save_file)\n",
    "\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(~np.equal(c.W, pullW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(~np.equal(c.b, pullB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 16)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reshapedW = c.W.reshape(784 * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(~np.equal(c.W, reshapedW.reshape(784, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "\n",
    "export_weights_json = {\n",
    "    \"W_rows\": c.W.shape[0],\n",
    "    \"W_columns\": c.W.shape[1],\n",
    "    \"b_entries\": c.b.shape[0],\n",
    "    \"W\": list(c.W.reshape(784 * (np.max(tr_all_y) + 1))),\n",
    "    \"b\": list(c.b),\n",
    "    \"class_map\": {y: x for x, y in name_class_list},\n",
    "    \"count_map\": {x: y for x, y in collections.Counter(map(lambda pair: '_'.join(pair[0].rsplit('_')[:-1]), name_class_list)).iteritems()}\n",
    "}\n",
    "\n",
    "save_file = open('weights.json', 'wb')\n",
    "json.dump(export_weights_json, save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'traditional_dragon_00.png',\n",
       " 1: 'traditional_dragon_01.png',\n",
       " 2: 'traditional_dragon_02.png',\n",
       " 3: 'traditional_dragon_03.png',\n",
       " 4: 'traditional_dragon_04.png',\n",
       " 5: 'traditional_dragon_05.png',\n",
       " 6: 'traditional_dragon_06.png',\n",
       " 7: 'traditional_dragon_07.png',\n",
       " 8: 'traditional_dragon_08.png',\n",
       " 9: 'traditional_dragon_09.png',\n",
       " 10: 'traditional_dragon_10.png',\n",
       " 11: 'traditional_dragon_11.png',\n",
       " 12: 'traditional_dragon_12.png',\n",
       " 13: 'traditional_dragon_13.png',\n",
       " 14: 'traditional_dragon_14.png',\n",
       " 15: 'traditional_dragon_15.png'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{y: x for x, y in name_class_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = 'as_fda_FDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "v = collections.Counter(map(lambda pair: '_'.join(pair[0].rsplit('_')[:-1]), name_class_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'traditional_dragon': 16}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:y for x,y in v.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
